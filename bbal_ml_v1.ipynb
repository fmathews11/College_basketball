{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_columns', None)\n",
    "from sklearn.model_selection import train_test_split, cross_val_score,cross_validate, GridSearchCV, KFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sportsreference.ncaab.teams import Teams\n",
    "from sportsreference.ncaab.teams import Team\n",
    "from sportsreference.ncaab.roster import Player\n",
    "from tqdm import tqdm\n",
    "from sportsreference.ncaab.boxscore import Boxscore\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import xgboost as xgb\n",
    "from pprint import pprint\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"ml_df_l3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Frank\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "cols_to_drop = [0,71,72,74,75,78,79,7,8,17,42,43,62,73]\n",
    "df = df.drop(columns = [df.columns[i] for i in cols_to_drop],axis = 1)\n",
    "X = df.drop('result',1)\n",
    "y = df.result\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0': {'f1-score': 0.9839749959350327,\n",
      "       'precision': 0.983708413105516,\n",
      "       'recall': 0.9842417232904438,\n",
      "       'support': 27668},\n",
      " '1': {'f1-score': 0.9839657260615702,\n",
      "       'precision': 0.9842326052365109,\n",
      "       'recall': 0.9836989915784147,\n",
      "       'support': 27667},\n",
      " 'accuracy': 0.9839703623384838,\n",
      " 'macro avg': {'f1-score': 0.9839703609983015,\n",
      "               'precision': 0.9839705091710135,\n",
      "               'recall': 0.9839703574344292,\n",
      "               'support': 55335},\n",
      " 'weighted avg': {'f1-score': 0.9839703610820627,\n",
      "                  'precision': 0.9839705044344802,\n",
      "                  'recall': 0.9839703623384838,\n",
      "                  'support': 55335}}\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators = 250,n_jobs = -1)\n",
    "clf.fit(X_train,y_train)\n",
    "y_train_pred = clf.predict(X_train)\n",
    "pprint(classification_report(y_train,y_train_pred,output_dict = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0': {'f1-score': 0.7330487870765574,\n",
      "       'precision': 0.7304834715193281,\n",
      "       'recall': 0.735632183908046,\n",
      "       'support': 9222},\n",
      " '1': {'f1-score': 0.7311898155704261,\n",
      "       'precision': 0.733784669141734,\n",
      "       'recall': 0.7286132494849832,\n",
      "       'support': 9223},\n",
      " 'accuracy': 0.7321225264299268,\n",
      " 'macro avg': {'f1-score': 0.7321193013234917,\n",
      "               'precision': 0.732134070330531,\n",
      "               'recall': 0.7321227166965145,\n",
      "               'support': 18445},\n",
      " 'weighted avg': {'f1-score': 0.7321192509312037,\n",
      "                  'precision': 0.7321341598181327,\n",
      "                  'recall': 0.7321225264299268,\n",
      "                  'support': 18445}}\n"
     ]
    }
   ],
   "source": [
    "pprint(classification_report(y_test,clf.predict(X_test),output_dict = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>home</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>win_percentage</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>opp_win_percentage</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>opp_simple_rating_system</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>simple_rating_system</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>opp_offensive_rating</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>offensive_rating</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>allowed_true_shooting_percentage</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>opp_true_shooting_percentage_allowed</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>opp_effective_field_goal_percentage_allowed</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>true_shooting_percentage</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>allowed_effective_field_goal_percentage</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>allowed_field_goal_percentage</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>opp_true_shooting_percentage</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>opp_field_goal_percentage_allowed</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>opp_field_goal_percentage</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>field_goal_percentage</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>opp_turnover_percentage</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>turnover_percentage</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>opp_two_point_field_goal_percentage_allowed</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>allowed_two_point_field_goal_percentage</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>total_rebound_percentage</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>opp_total_rebound_percentage_allowed</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>opp_total_rebound_percentage</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>opp_effective_field_goal_percentage</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        feature  importance\n",
       "64                                         home        0.07\n",
       "31                               win_percentage        0.06\n",
       "49                           opp_win_percentage        0.06\n",
       "41                     opp_simple_rating_system        0.04\n",
       "23                         simple_rating_system        0.04\n",
       "38                         opp_offensive_rating        0.02\n",
       "6                              offensive_rating        0.02\n",
       "20             allowed_true_shooting_percentage        0.02\n",
       "62         opp_true_shooting_percentage_allowed        0.02\n",
       "52  opp_effective_field_goal_percentage_allowed        0.02\n",
       "29                     true_shooting_percentage        0.01\n",
       "10      allowed_effective_field_goal_percentage        0.01\n",
       "11                allowed_field_goal_percentage        0.01\n",
       "47                 opp_true_shooting_percentage        0.01\n",
       "53            opp_field_goal_percentage_allowed        0.01\n",
       "35                    opp_field_goal_percentage        0.01\n",
       "3                         field_goal_percentage        0.01\n",
       "48                      opp_turnover_percentage        0.01\n",
       "30                          turnover_percentage        0.01\n",
       "60  opp_two_point_field_goal_percentage_allowed        0.01\n",
       "18      allowed_two_point_field_goal_percentage        0.01\n",
       "28                     total_rebound_percentage        0.01\n",
       "61         opp_total_rebound_percentage_allowed        0.01\n",
       "46                 opp_total_rebound_percentage        0.01\n",
       "34          opp_effective_field_goal_percentage        0.01"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp_dict = {key:[] for key in ('feature','importance')}\n",
    "for feat,imp in zip(X_train.columns,clf.feature_importances_):\n",
    "    imp_dict['feature'].append(feat)\n",
    "    imp_dict['importance'].append(imp)\n",
    "    \n",
    "imp_df = pd.DataFrame.from_dict(imp_dict)\n",
    "imp_df.sort_values('importance',ascending = False).head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_dict = {key:[] for key in ('trees','fit_time','score_time','test_score')}\n",
    "for trees in tqdm(range(50,1000,50)):\n",
    "    clf = RandomForestClassifier(n_estimators = trees,n_jobs = -1)\n",
    "    cv_results = cross_validate(clf,X_train,y_train,cv = 3)\n",
    "    avg = np.mean(cv_results['test_score'])\n",
    "    master_dict['trees'].append(trees)\n",
    "    master_dict['fit_time'].append(cv_results['fit_time'])\n",
    "    master_dict['score_time'].append(cv_results['score_time'])\n",
    "    master_dict['test_score'].append(avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.from_dict(master_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_outer = KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "# enumerate splits\n",
    "outer_results = list()\n",
    "param_dict = {key:[] for key in ('best_score','best_params')}\n",
    "for train_ix, test_ix in tqdm(cv_outer.split(X)):\n",
    "\n",
    "    X_train, X_test = X.iloc[train_ix, :], X.iloc[test_ix, :]\n",
    "    y_train, y_test = y.iloc[train_ix], y.iloc[test_ix]\n",
    "    # configure the cross-validation procedure\n",
    "    cv_inner = KFold(n_splits=3, shuffle=True, random_state=1)\n",
    "    # define the model\n",
    "    model = RandomForestClassifier(random_state=1,n_jobs = -1)\n",
    "    # define search space\n",
    "    space = dict()\n",
    "    space['n_estimators'] = [100, 500,1000]\n",
    "    space['max_features'] = [3,6,12,24]\n",
    "    # define search\n",
    "    search = GridSearchCV(model, space, scoring='accuracy', cv=cv_inner, refit=True)\n",
    "    # execute search\n",
    "    result = search.fit(X_train, y_train)\n",
    "    # get the best performing model fit on the whole training set\n",
    "    best_model = result.best_estimator_\n",
    "    # evaluate model on the hold out dataset\n",
    "    yhat = best_model.predict(X_test)\n",
    "    # evaluate the model\n",
    "    acc = accuracy_score(y_test, yhat)\n",
    "    # store the result\n",
    "    outer_results.append(acc)\n",
    "    # report progress\n",
    "    print('>acc=%.3f, est=%.3f, cfg=%s' % (acc, result.best_score_, result.best_params_))\n",
    "    param_dict['best_score'].append(result.best_score_)\n",
    "    param_dict['best_params'].append(result.best_params_)\n",
    "    # summarize the estimated performance of the model\n",
    "    print('Accuracy: %.3f (%.3f)' % (np.mean(outer_results), np.std(outer_results)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_dict = {key:[] for key in ('max_features','trees','training_acc','testing_acc','testing_std')}\n",
    "ests = [6,12,18,24,30,36,42]\n",
    "trees = [100,250,500,1000,1500]\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,stratify = y,random_state = 3)\n",
    "for i in tqdm(ests):\n",
    "    for j in trees:\n",
    "        clf = RandomForestClassifier(n_estimators = j,max_features = i,n_jobs = -1,verbose = 1,class_weight = 'balanced')\n",
    "        clf.fit(X_train,y_train)\n",
    "        score1 = clf.score(X_train,y_train)\n",
    "        master_dict['training_acc'].append(score1)\n",
    "        score = cross_val_score(clf,X_train,y_train,cv = 5)\n",
    "        #score = np.mean(score)\n",
    "        master_dict['testing_acc'].append(np.mean(score))\n",
    "        master_dict['testing_std'].append(np.std(score))  \n",
    "        master_dict['max_features'].append(i)\n",
    "        master_dict['trees'].append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.from_dict(master_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_dict = {key:[] for key in ('trees','acc','std')}\n",
    "for i in tqdm(range(50,1500,50)):\n",
    "    clf = xgb.XGBClassifier(n_jobs = -1,n_estimators = i)\n",
    "    score = cross_val_score(clf,X_train,y_train,cv = 5,n_jobs = -1)\n",
    "    master_dict['acc'].append(np.mean(score))\n",
    "    master_dict['std'].append(np.std(score))\n",
    "    master_dict['trees'].append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.from_dict(master_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_dict = {key:[] for key in ('md','acc','std')}\n",
    "for i in tqdm(range(1,20)):\n",
    "    clf = xgb.XGBClassifier(n_jobs = -1,max_depth = i)\n",
    "    score = cross_val_score(clf,X_train,y_train,cv = 5,n_jobs = -1)\n",
    "    master_dict['acc'].append(np.mean(score))\n",
    "    master_dict['std'].append(np.std(score))\n",
    "    master_dict['md'].append(i)\n",
    "pd.DataFrame.from_dict(master_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
       "              colsample_bynode=None, colsample_bytree=None, gamma=None,\n",
       "              gpu_id=None, importance_type='gain', interaction_constraints=None,\n",
       "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              random_state=None, reg_alpha=None, reg_lambda=None,\n",
       "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
       "              validate_parameters=None, verbosity=None)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb.XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_dict = {key:[] for key in ('lr','acc','std')}\n",
    "for i in tqdm(np.linspace(0.5,2,10)):\n",
    "    clf = xgb.XGBClassifier(n_jobs = -1,max_depth = i)\n",
    "    score = cross_val_score(clf,X_train,y_train,cv = 5,n_jobs = -1)\n",
    "    master_dict['acc'].append(np.mean(score))\n",
    "    master_dict['std'].append(np.std(score))\n",
    "    master_dict['lr'].append(i)\n",
    "pd.DataFrame.from_dict(master_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7539712659257252 0.7495798319327731\n"
     ]
    }
   ],
   "source": [
    "clf = xgb.XGBClassifier(n_jobs = -1,\n",
    "                        max_depth = 2,\n",
    "                       subsample = 1,\n",
    "                       n_estimators = 1000,\n",
    "                       learning_rate = 0.0025)\n",
    "clf.fit(X_train,y_train)\n",
    "score1 = accuracy_score(y_train,clf.predict(X_train))\n",
    "score2 = accuracy_score(y_test,clf.predict(X_test))\n",
    "print(score1,score2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
